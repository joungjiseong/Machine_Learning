from tensorflow.keras.models import load_model
import pickle
import pandas as pd
import numpy as np
import re
from tensorflow.keras.preprocessing.sequence import pad_sequences

# í•¨ìˆ˜ ì •ì˜
def count_special_characters(text):
    return len(re.findall(r'[^\w\s]', text))

def count_emojis(text):
    emoji_pattern = re.compile(
        "[\U0001F600-\U0001F64F"
        "\U0001F300-\U0001F5FF"
        "\U0001F680-\U0001F6FF"
        "\U0001F700-\U0001F77F"
        "\U0001F780-\U0001F7FF"
        "\U0001F800-\U0001F8FF"
        "\U0001F900-\U0001F9FF"
        "\U0001FA00-\U0001FA6F"
        "\U0001FA70-\U0001FAFF"
        "\U00002702-\U000027B0"
        "]+", flags=re.UNICODE)
    return len(emoji_pattern.findall(text))

# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
loaded_model = load_model('spamModel.h5')
with open('tokenizer.pkl', 'rb') as file:
    tokenizer = pickle.load(file)

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
test_data = pd.DataFrame({
    'MailName': [
        "í•œì • ê¸°ê°„! ìµœì‹  ìŠ¤ë§ˆíŠ¸í° 90% í• ì¸! ì§€ê¸ˆ ë°”ë¡œ êµ¬ë§¤í•˜ì„¸ìš” ğŸ‰",             #ìŠ¤íŒ¸ ì œëª©
        "ë‹¹ì‹ ì˜ ê³„ì •ì´ í•´í‚¹ë˜ì—ˆìŠµë‹ˆë‹¤. ë¹„ë°€ë²ˆí˜¸ë¥¼ ì¬ì„¤ì •í•˜ì„¸ìš”âš ï¸",                 #ìŠ¤íŒ¸ ì œëª©
        "ë‹¹ì²¨ ì¶•í•˜ë“œë¦½ë‹ˆë‹¤! â˜˜ï¸ ì§€ê¸ˆ ë°”ë¡œ í™•ì¸í•´ ìƒí’ˆì„ ìˆ˜ë ¹í•˜ì„¸ìš” ğŸ",            #ìŠ¤íŒ¸ ì œëª©
        "ğŸ“¢ ì¤‘ìš”í•œ ê³µì§€ì‚¬í•­ í™•ì¸ ë°”ëë‹ˆë‹¤!",       #ì •ìƒ ì œëª©
        "ìƒˆë¡œìš´ ê¸°ê¸°ì—ì„œ ë¡œê·¸ì¸ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤ âš ï¸",            #ì •ìƒ ì œëª©
        "2024ë…„ 1í•™ê¸° ìˆ˜ì—… ìš´ì˜ ë°©ì‹ë³„ ì¶œì„ ì²´í¬ ì•ˆë‚´",                 #ì •ìƒ ì œëª©
    ],
    'special_char_count': [
        count_special_characters("í•œì • ê¸°ê°„! ìµœì‹  ìŠ¤ë§ˆíŠ¸í° 90% í• ì¸! ì§€ê¸ˆ ë°”ë¡œ êµ¬ë§¤í•˜ì„¸ìš” ğŸ‰"),
        count_special_characters("ë‹¹ì‹ ì˜ ê³„ì •ì´ í•´í‚¹ë˜ì—ˆìŠµë‹ˆë‹¤. ë¹„ë°€ë²ˆí˜¸ë¥¼ ì¬ì„¤ì •í•˜ì„¸ìš”âš ï¸"),
        count_special_characters("ë‹¹ì²¨ ì¶•í•˜ë“œë¦½ë‹ˆë‹¤! â˜˜ï¸ ì§€ê¸ˆ ë°”ë¡œ í™•ì¸í•´ ìƒí’ˆì„ ìˆ˜ë ¹í•˜ì„¸ìš” ğŸ"),
        count_special_characters("ğŸ“¢ ì¤‘ìš”í•œ ê³µì§€ì‚¬í•­ í™•ì¸ ë°”ëë‹ˆë‹¤! âš ï¸"),
        count_special_characters("ìƒˆë¡œìš´ ê¸°ê¸°ì—ì„œ ë¡œê·¸ì¸ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤"),
        count_special_characters("2024ë…„ 1í•™ê¸° ìˆ˜ì—… ìš´ì˜ ë°©ì‹ë³„ ì¶œì„ ì²´í¬ ì•ˆë‚´"),
    ],
    'emoji_count': [
        count_emojis("í•œì • ê¸°ê°„! ìµœì‹  ìŠ¤ë§ˆíŠ¸í° 90% í• ì¸! ì§€ê¸ˆ ë°”ë¡œ êµ¬ë§¤í•˜ì„¸ìš” ğŸ‰"),
        count_emojis("ë‹¹ì‹ ì˜ ê³„ì •ì´ í•´í‚¹ë˜ì—ˆìŠµë‹ˆë‹¤. ë¹„ë°€ë²ˆí˜¸ë¥¼ ì¬ì„¤ì •í•˜ì„¸ìš”âš ï¸"),
        count_emojis("ë‹¹ì²¨ ì¶•í•˜ë“œë¦½ë‹ˆë‹¤! â˜˜ï¸ ì§€ê¸ˆ ë°”ë¡œ í™•ì¸í•´ ìƒí’ˆì„ ìˆ˜ë ¹í•˜ì„¸ìš” ğŸ"),
        count_emojis("ğŸ“¢ ì¤‘ìš”í•œ ê³µì§€ì‚¬í•­ í™•ì¸ ë°”ëë‹ˆë‹¤! âš ï¸"),
        count_emojis("ìƒˆë¡œìš´ ê¸°ê¸°ì—ì„œ ë¡œê·¸ì¸ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤"),
        count_emojis("2024ë…„ 1í•™ê¸° ìˆ˜ì—… ìš´ì˜ ë°©ì‹ë³„ ì¶œì„ ì²´í¬ ì•ˆë‚´"),
    ]
})

X_test = test_data[['MailName', 'special_char_count', 'emoji_count']]
max_len = 64

# ì „ì²˜ë¦¬
X_test_encoded = tokenizer.texts_to_sequences(X_test['MailName'])
X_test_padded = pad_sequences(X_test_encoded, maxlen=max_len)
X_test_special = np.hstack([X_test[['special_char_count', 'emoji_count']].values])

# ì˜ˆì¸¡ ì‹¤í–‰
predictions = loaded_model.predict([X_test_padded, X_test_special])
for i, pred in enumerate(predictions):
    print(f"ì´ë©”ì¼: {X_test['MailName'].iloc[i]}")
    print(f"ì˜ˆì¸¡ í™•ë¥ : {pred[0]:.4f}")
    print("ì˜ˆì¸¡ ê²°ê³¼: ìŠ¤íŒ¸" if pred[0] < 0.2 else "ì˜ˆì¸¡ ê²°ê³¼: ì •ìƒ")
